{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\daksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\daksh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like sleeping\n",
      "I love pizza and cheese\n",
      "I hate cooking\n",
      "I like cooking\n",
      "I like racing cars\n",
      "I don't like burgers\n",
      "I am jobless\n",
      "I am an intern\n",
      "data is bad\n",
      "data is good\n"
     ]
    }
   ],
   "source": [
    "list_1 = [\"I like sleeping\",\"I love pizza and cheese\",\"I hate cooking\", \"I like cooking\",\"I like racing cars\",\"I don't like burgers\", \"I am jobless\", \"I am an intern\", \"data is bad\", \"data is good\"]\n",
    "for i in list_1:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(doc_1,doc_2):\n",
    "  words_doc1 = set(doc_1.lower().split()) \n",
    "  words_doc2 = set(doc_2.lower().split())\n",
    "  intersection = words_doc1.intersection(words_doc2)\n",
    "  union = words_doc1.union(words_doc2)\n",
    "  return float((len(intersection)) / len(union)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "def cosine_similarity(X,Y):\n",
    "    X_list = word_tokenize(X) \n",
    "    Y_list = word_tokenize(Y)\n",
    "\n",
    "    sw = stopwords.words('english') \n",
    "    l1 =[];l2 =[]\n",
    "\n",
    "    #remove stop words\n",
    "    X_set = {w for w in X_list if not w in sw} \n",
    "    Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "    rvector = X_set.union(Y_set) \n",
    "\n",
    "    for w in rvector:\n",
    "        if w in X_set: l1.append(1) \n",
    "        else: l1.append(0)\n",
    "        if w in Y_set: l2.append(1)\n",
    "        else: l2.append(0)\n",
    "\n",
    "    c = 0\n",
    "    for i in range(len(rvector)):\n",
    "        c+=l1[i]*l2[i]\n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    return(cosine*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = []\n",
    "similarity_list = []\n",
    "similarity_list2 = []\n",
    "for i in range(len(list_1)):\n",
    "    string_list.append(list_1[i])\n",
    "    similarity_list.append(cosine_similarity(user_input,list_1[i]))\n",
    "    similarity_list2.append(Jaccard(user_input,list_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I like sleeping', 'I love pizza and cheese', 'I hate cooking', 'I like cooking', 'I like racing cars', \"I don't like burgers\", 'I am jobless', 'I am an intern', 'data is bad', 'data is good']\n",
      "[81.64965809277261, 35.35533905932737, 40.824829046386306, 81.64965809277261, 70.71067811865474, 70.71067811865474, 50.0, 50.0, 0.0, 0.0]\n",
      "[66.66666666666666, 16.666666666666664, 25.0, 66.66666666666666, 50.0, 50.0, 25.0, 20.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(string_list)\n",
    "print(similarity_list)\n",
    "print(similarity_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like sleeping\n",
      "I like cooking\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity_list)):\n",
    "    if similarity_list[i] and similarity_list2[i] > 50:\n",
    "        print(string_list[i])\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7339233bad5de19f5ecc99bec74f4ed72eabe43e99bcba736294cbec8ddb2a6f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
